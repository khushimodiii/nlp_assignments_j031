{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11957,"sourceType":"datasetVersion","datasetId":8542},{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715},{"sourceId":12975154,"sourceType":"datasetVersion","datasetId":8212330}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-06T05:21:05.202531Z","iopub.execute_input":"2025-09-06T05:21:05.202782Z","iopub.status.idle":"2025-09-06T05:21:07.408315Z","shell.execute_reply.started":"2025-09-06T05:21:05.202756Z","shell.execute_reply":"2025-09-06T05:21:07.407440Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Part 1","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Load the IMDB dataset\ndf = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')  # file should have columns: review, sentiment\n\n# Map sentiment to int\ndf['label'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n\n# Basic cleaningâ€”optional: remove HTML tags\nimport re\ndf['clean_review'] = df['review'].apply(lambda x: re.sub(r'<.*?>', ' ', x))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T05:21:29.013543Z","iopub.execute_input":"2025-09-06T05:21:29.013821Z","iopub.status.idle":"2025-09-06T05:21:31.148603Z","shell.execute_reply.started":"2025-09-06T05:21:29.013802Z","shell.execute_reply":"2025-09-06T05:21:31.147692Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Hyperparameters\nMAX_NUM_WORDS = 20000\nMAX_LEN = 200\n\ntokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\ntokenizer.fit_on_texts(df['clean_review'])\nsequences = tokenizer.texts_to_sequences(df['clean_review'])\nword_index = tokenizer.word_index\nprint('Vocabulary size:', len(word_index))\n\n# Pad sequences for batching\nX_data = pad_sequences(sequences, maxlen=MAX_LEN)\ny_data = df['label'].values\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T05:26:40.341965Z","iopub.execute_input":"2025-09-06T05:26:40.342347Z","iopub.status.idle":"2025-09-06T05:26:54.835106Z","shell.execute_reply.started":"2025-09-06T05:26:40.342318Z","shell.execute_reply":"2025-09-06T05:26:54.834169Z"}},"outputs":[{"name":"stdout","text":"Vocabulary size: 124245\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T05:27:39.215532Z","iopub.execute_input":"2025-09-06T05:27:39.215836Z","iopub.status.idle":"2025-09-06T05:27:39.434857Z","shell.execute_reply.started":"2025-09-06T05:27:39.215816Z","shell.execute_reply":"2025-09-06T05:27:39.433855Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Load GloVe Embeddings\n# Build embedding matrix\nembedding_index = {}\nwith open('/kaggle/input/glove6b50dtxt/glove.6B.50d.txt', encoding='utf8') as f:\n    for line in f:\n        values = line.split()\n        word = values[0]\n        coeffs = np.asarray(values[1:], dtype='float32')\n        embedding_index[word] = coeffs\n\nEMBEDDING_DIM = 50\nembedding_matrix = np.zeros((MAX_NUM_WORDS, EMBEDDING_DIM))\nfor word, i in tokenizer.word_index.items():\n    if i < MAX_NUM_WORDS:\n        embedding_vector = embedding_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[i] = embedding_vector\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T05:34:05.769089Z","iopub.execute_input":"2025-09-06T05:34:05.769970Z","iopub.status.idle":"2025-09-06T05:34:12.289256Z","shell.execute_reply.started":"2025-09-06T05:34:05.769944Z","shell.execute_reply":"2025-09-06T05:34:12.288343Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Vanilla RNN with GloVe (using PyTorch)\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass RNNClassifier(nn.Module):\n    def __init__(self, embedding_matrix):\n        super(RNNClassifier, self).__init__()\n        num_embeddings, embedding_dim = embedding_matrix.shape\n        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix), freeze=True)\n        self.rnn = nn.RNN(embedding_dim, 64, batch_first=True)\n        self.fc = nn.Linear(64, 1)\n    \n    def forward(self, x):\n        x = self.embedding(x)\n        h_seq, _ = self.rnn(x)\n        out = self.fc(h_seq[:, -1, :])\n        return torch.sigmoid(out).squeeze()\n\n# DataLoader setup for PyTorch\nfrom torch.utils.data import TensorDataset, DataLoader\n\nBATCH_SIZE = 128\ntrain_data = TensorDataset(torch.LongTensor(X_train), torch.FloatTensor(y_train))\ntest_data = TensorDataset(torch.LongTensor(X_test), torch.FloatTensor(y_test))\n\ntrain_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=BATCH_SIZE)\n\n# Model, loss, optimizer\nmodel = RNNClassifier(embedding_matrix)\nloss_fn = nn.BCELoss()\noptimizer = optim.Adam(model.parameters())\n\n# Training Loop\nn_epochs = 2\nmodel.train()\nfor epoch in range(n_epochs):\n    for xb, yb in train_loader:\n        optimizer.zero_grad()\n        preds = model(xb)\n        loss = loss_fn(preds, yb)\n        loss.backward()\n        optimizer.step()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T05:34:23.460188Z","iopub.execute_input":"2025-09-06T05:34:23.460483Z","iopub.status.idle":"2025-09-06T05:35:42.167706Z","shell.execute_reply.started":"2025-09-06T05:34:23.460456Z","shell.execute_reply":"2025-09-06T05:35:42.166570Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# LSTM with GloVe\nclass LSTMClassifier(nn.Module):\n    def __init__(self, embedding_matrix):\n        super(LSTMClassifier, self).__init__()\n        num_embeddings, embedding_dim = embedding_matrix.shape\n        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix), freeze=True)\n        self.lstm = nn.LSTM(embedding_dim, 64, batch_first=True)\n        self.fc = nn.Linear(64, 1)\n    \n    def forward(self, x):\n        x = self.embedding(x)\n        h_seq, _ = self.lstm(x)\n        out = self.fc(h_seq[:, -1, :])\n        return torch.sigmoid(out).squeeze()\n\n# Instantiate/Train as for RNN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T05:35:44.960116Z","iopub.execute_input":"2025-09-06T05:35:44.960978Z","iopub.status.idle":"2025-09-06T05:35:44.966945Z","shell.execute_reply.started":"2025-09-06T05:35:44.960952Z","shell.execute_reply":"2025-09-06T05:35:44.966068Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"#Vanilla RNN & LSTM with trainable torch.nn.Embedding (Random Initialization)\n# For on-the-fly embeddings, replace the Embedding line as:\nself.embedding = nn.Embedding(MAX_NUM_WORDS, EMBEDDING_DIM)\n# Instantiate RNNClassifier or LSTMClassifier as above, and train.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T05:36:37.887140Z","iopub.execute_input":"2025-09-06T05:36:37.887480Z","iopub.status.idle":"2025-09-06T05:36:37.933656Z","shell.execute_reply.started":"2025-09-06T05:36:37.887458Z","shell.execute_reply":"2025-09-06T05:36:37.932452Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1528986944.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Vanilla RNN & LSTM with trainable torch.nn.Embedding (Random Initialization)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# For on-the-fly embeddings, replace the Embedding line as:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_NUM_WORDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# Instantiate RNNClassifier or LSTMClassifier as above, and train.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"],"ename":"NameError","evalue":"name 'self' is not defined","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"EMBEDDING_DIM = 50\nembedding_index = {}\n\nwith open('/kaggle/input/glove6b50dtxt/glove.6B.50d.txt', encoding='utf8') as f:\n    for line in f:\n        values = line.split()\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype='float32')\n        embedding_index[word] = coefs\n\nembedding_matrix = np.zeros((MAX_NUM_WORDS, EMBEDDING_DIM))\nfor word, i in tokenizer.word_index.items():\n    if i < MAX_NUM_WORDS:\n        vec = embedding_index.get(word)\n        if vec is not None:\n            embedding_matrix[i] = vec\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T05:40:30.473846Z","iopub.execute_input":"2025-09-06T05:40:30.474691Z","iopub.status.idle":"2025-09-06T05:40:35.616355Z","shell.execute_reply.started":"2025-09-06T05:40:30.474665Z","shell.execute_reply":"2025-09-06T05:40:35.615412Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import TensorDataset, DataLoader\n\nBATCH_SIZE = 128\n\nX_train_torch = torch.LongTensor(X_train)\ny_train_torch = torch.FloatTensor(y_train)\nX_test_torch = torch.LongTensor(X_test)\ny_test_torch = torch.FloatTensor(y_test)\n\ntrain_ds = TensorDataset(X_train_torch, y_train_torch)\ntest_ds = TensorDataset(X_test_torch, y_test_torch)\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T05:40:45.176318Z","iopub.execute_input":"2025-09-06T05:40:45.177150Z","iopub.status.idle":"2025-09-06T05:40:45.219586Z","shell.execute_reply.started":"2025-09-06T05:40:45.177126Z","shell.execute_reply":"2025-09-06T05:40:45.218706Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import torch.nn as nn\n\nclass RNNClassifier(nn.Module):\n    def __init__(self, embedding_matrix=None, trainable=False):\n        super().__init__()\n        num_emb, emb_dim = embedding_matrix.shape if embedding_matrix is not None else (MAX_NUM_WORDS, EMBEDDING_DIM)\n        if embedding_matrix is not None:\n            self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix), freeze=not trainable)\n        else:\n            self.embedding = nn.Embedding(num_emb, emb_dim)\n        self.rnn = nn.RNN(emb_dim, 64, batch_first=True)\n        self.fc = nn.Linear(64, 1)\n    def forward(self, x):\n        x = self.embedding(x)\n        out, _ = self.rnn(x)\n        return torch.sigmoid(self.fc(out[:, -1, :])).squeeze()\n\nclass LSTMClassifier(nn.Module):\n    def __init__(self, embedding_matrix=None, trainable=False):\n        super().__init__()\n        num_emb, emb_dim = embedding_matrix.shape if embedding_matrix is not None else (MAX_NUM_WORDS, EMBEDDING_DIM)\n        if embedding_matrix is not None:\n            self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix), freeze=not trainable)\n        else:\n            self.embedding = nn.Embedding(num_emb, emb_dim)\n        self.lstm = nn.LSTM(emb_dim, 64, batch_first=True)\n        self.fc = nn.Linear(64, 1)\n    def forward(self, x):\n        x = self.embedding(x)\n        out, _ = self.lstm(x)\n        return torch.sigmoid(self.fc(out[:, -1, :])).squeeze()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T05:40:56.332506Z","iopub.execute_input":"2025-09-06T05:40:56.333043Z","iopub.status.idle":"2025-09-06T05:40:56.342937Z","shell.execute_reply.started":"2025-09-06T05:40:56.332985Z","shell.execute_reply":"2025-09-06T05:40:56.341900Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def train_model(model, train_loader, n_epochs=2):\n    optimizer = torch.optim.Adam(model.parameters())\n    loss_fn = nn.BCELoss()\n    model.train()\n    for epoch in range(n_epochs):\n        total_loss = 0\n        for xb, yb in train_loader:\n            optimizer.zero_grad()\n            preds = model(xb)\n            loss = loss_fn(preds, yb)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        print(f\"Epoch {epoch+1} - Loss: {total_loss / len(train_loader)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T05:41:12.132635Z","iopub.execute_input":"2025-09-06T05:41:12.133232Z","iopub.status.idle":"2025-09-06T05:41:12.138910Z","shell.execute_reply.started":"2025-09-06T05:41:12.133205Z","shell.execute_reply":"2025-09-06T05:41:12.138071Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\ndef evaluate_model(model, loader):\n    model.eval()\n    preds, y_true = [], []\n    with torch.no_grad():\n        for xb, yb in loader:\n            outputs = model(xb)\n            preds += outputs.round().detach().cpu().numpy().tolist()\n            y_true += yb.cpu().numpy().tolist()\n    return f1_score(y_true, preds)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T05:41:20.975606Z","iopub.execute_input":"2025-09-06T05:41:20.975915Z","iopub.status.idle":"2025-09-06T05:41:20.981679Z","shell.execute_reply.started":"2025-09-06T05:41:20.975877Z","shell.execute_reply":"2025-09-06T05:41:20.980792Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# RNN with GloVe\nrnn_glove_model = RNNClassifier(embedding_matrix, trainable=False)\ntrain_model(rnn_glove_model, train_loader, n_epochs=2)\n# LSTM with GloVe\nlstm_glove_model = LSTMClassifier(embedding_matrix, trainable=False)\ntrain_model(lstm_glove_model, train_loader, n_epochs=2)\n# RNN with trainable embeddings (random init)\nrnn_onfly_model = RNNClassifier(None, trainable=True)\ntrain_model(rnn_onfly_model, train_loader, n_epochs=2)\n# LSTM with trainable embeddings (random init)\nlstm_onfly_model = LSTMClassifier(None, trainable=True)\ntrain_model(lstm_onfly_model, train_loader, n_epochs=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T05:43:50.380173Z","iopub.execute_input":"2025-09-06T05:43:50.380477Z","iopub.status.idle":"2025-09-06T05:51:15.169241Z","shell.execute_reply.started":"2025-09-06T05:43:50.380456Z","shell.execute_reply":"2025-09-06T05:51:15.168341Z"}},"outputs":[{"name":"stdout","text":"Epoch 1 - Loss: 0.6534062844876665\nEpoch 2 - Loss: 0.6326016786570747\nEpoch 1 - Loss: 0.6766700580858955\nEpoch 2 - Loss: 0.6517319917297972\nEpoch 1 - Loss: 0.6577003588691687\nEpoch 2 - Loss: 0.6193911806463053\nEpoch 1 - Loss: 0.6075078097585672\nEpoch 2 - Loss: 0.42799272276342104\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"print(\"RNN + GloVe:\", evaluate_model(rnn_glove_model, test_loader))\nprint(\"LSTM + GloVe:\", evaluate_model(lstm_glove_model, test_loader))\nprint(\"RNN + trainable:\", evaluate_model(rnn_onfly_model, test_loader))\nprint(\"LSTM + trainable:\", evaluate_model(lstm_onfly_model, test_loader))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T05:51:23.753471Z","iopub.execute_input":"2025-09-06T05:51:23.754368Z","iopub.status.idle":"2025-09-06T05:51:33.882560Z","shell.execute_reply.started":"2025-09-06T05:51:23.754341Z","shell.execute_reply":"2025-09-06T05:51:33.881788Z"}},"outputs":[{"name":"stdout","text":"RNN + GloVe: 0.7229307540871353\nLSTM + GloVe: 0.6967895362663495\nRNN + trainable: 0.7060838362420486\nLSTM + trainable: 0.8349203356274159\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"## Part 2","metadata":{}},{"cell_type":"code","source":"import re\nfrom datetime import datetime\n\n# Month mapping for name to number\nmonth_map = {\n    'jan': '01', 'january': '01',\n    'feb': '02', 'february': '02',\n    'mar': '03', 'march': '03',\n    'apr': '04', 'april': '04',\n    'may': '05',\n    'jun': '06', 'june': '06',\n    'jul': '07', 'july': '07',\n    'aug': '08', 'august': '08',\n    'sep': '09', 'sept': '09', 'september': '09',\n    'oct': '10', 'october': '10',\n    'nov': '11', 'november': '11',\n    'dec': '12', 'december': '12'\n}\n\ndef normalize_year(yy):\n    yy = int(yy)\n    if yy < 100:\n        return str(2000 + yy) if yy <= 30 else str(1900 + yy)  # heuristic cutoff\n    return str(yy)\n\ndef extract_date(text):\n    patterns = [\n        # 1. Day Month Year (e.g., 15th September 2021, 1 July 2023)\n        r'(?P<day>\\d{1,2})(?:st|nd|rd|th)?\\s+(?:of\\s+)?(?P<month>[a-zA-Z]+)[,]?\\s+(?P<year>\\d{2,4})',\n        # 2. Month Day Year (e.g., July 2, 2023)\n        r'(?P<month>[a-zA-Z]+)\\s+(?P<day>\\d{1,2})(?:st|nd|rd|th)?[,]?\\s+(?P<year>\\d{2,4})',\n        # 3. yyyy-mm-dd or yyyy/mm/dd or yyyy.mm.dd\n        r'(?P<year>\\d{4})[-/.](?P<month>\\d{1,2})[-/.](?P<day>\\d{1,2})',\n        # 4. dd/mm/yyyy or mm/dd/yyyy or dd.mm.yyyy etc.\n        r'(?P<day>\\d{1,2})[-/.](?P<month>\\d{1,2})[-/.](?P<year>\\d{2,4})',\n        # 5. yyyy (only for ISO-style within text)\n        # This is covered above, no isolated year capture here\n    ]\n    \n    for pattern in patterns:\n        match = re.search(pattern, text, re.IGNORECASE)\n        if match:\n            day = match.group('day')\n            month = match.group('month')\n            year = match.group('year')\n\n            # Normalize month if it's a name\n            if month.isalpha():\n                month_lower = month.lower()\n                month = month_map.get(month_lower[:3], None)\n                if not month:\n                    continue \n            \n            # Normalize year length (handle YY vs YYYY)\n            year = normalize_year(year)\n            \n            # Pad day and month with zeros\n            day = day.zfill(2)\n            month = month.zfill(2)\n\n            return f\"{day}/{month}/{year}\"\n    return None\n\n# Test inputs:\ntests = [\n    \"The event will take place on March 5, 2023.\",\n    \"Her birthday is on 07/08/1990\",\n    \"The deadline is 2022-12-31.\",\n    \"We met on 1st of January 2000.\",\n    \"The concert is scheduled for 15th September, 2021.\",\n    \"Let's catch up on 02.04.2022.\",\n    \"The project started on 5/6/19.\",\n    \"He was born on 1987/11/23.\",\n    \"Christmas is on 25th Dec 2024.\",\n    \"Submit your report by 08/31/2021.\",\n]\n\nfor t in tests:\n    print(f\"{t} -> {extract_date(t)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T06:04:00.573855Z","iopub.execute_input":"2025-09-06T06:04:00.574206Z","iopub.status.idle":"2025-09-06T06:04:00.585436Z","shell.execute_reply.started":"2025-09-06T06:04:00.574182Z","shell.execute_reply":"2025-09-06T06:04:00.584724Z"}},"outputs":[{"name":"stdout","text":"The event will take place on March 5, 2023. -> 05/03/2023\nHer birthday is on 07/08/1990 -> 07/08/1990\nThe deadline is 2022-12-31. -> 31/12/2022\nWe met on 1st of January 2000. -> 01/01/2000\nThe concert is scheduled for 15th September, 2021. -> 15/09/2021\nLet's catch up on 02.04.2022. -> 02/04/2022\nThe project started on 5/6/19. -> 05/06/2019\nHe was born on 1987/11/23. -> 23/11/1987\nChristmas is on 25th Dec 2024. -> 25/12/2024\nSubmit your report by 08/31/2021. -> 08/31/2021\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"## Part 3","metadata":{}},{"cell_type":"code","source":"import spacy\nimport string\n\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef switch_gender(text, target='female'):\n    # Define mappings male->female and female->male pronouns\n    pronoun_map = {\n        'male': {\n            'he': 'she', 'him': 'her', 'his': 'her', 'himself': 'herself',\n            'himself': 'herself', 'i': 'i', 'me': 'me', 'my': 'my', 'mine': 'mine',\n        },\n        'female': {\n            'she': 'he', 'her': ['him', 'his'], 'hers': 'his', 'herself': 'himself',\n            'i': 'i', 'me': 'me', 'my': 'my', 'mine': 'mine',\n        }\n    }\n\n    # Choose map depending on target\n    if target == 'female':\n        mapping = pronoun_map['male']\n    else:\n        mapping = pronoun_map['female']\n\n    doc = nlp(text)\n    result_tokens = []\n\n    # helper function to match case of original token to replacement\n    def match_case(original, replacement):\n        if original.isupper():\n            return replacement.upper()\n        if original[0].isupper():\n            return replacement.capitalize()\n        return replacement\n\n    for token in doc:\n        text_lower = token.text.lower()\n        replacement = None\n\n        # Special case: 'her' can map to 'him' or 'his' depending on POS tag\n        if target == 'female' and text_lower == 'her':\n            if token.pos_ == 'PRON':\n                replacement = 'him'  # objective pronoun\n            elif token.pos_ in ['DET', 'ADJ']:\n                replacement = 'his'  # possessive adjective\n        elif target == 'male' and text_lower == 'him':\n            # Reverse logic for 'him'\n            if token.pos_ == 'PRON':\n                replacement = 'her'\n            elif token.pos_ in ['DET', 'ADJ']:\n                replacement = 'her'\n\n        if not replacement and text_lower in mapping:\n            mapping_value = mapping[text_lower]\n            # For female->male her can map to list of two, handle appropriately\n            # Here we use first for pronoun substitution, fallback later\n            if isinstance(mapping_value, list):\n                # pick pronoun or possessive based on POS and dependency for better accuracy\n                if token.dep_ in ['dobj', 'pobj']:  # object\n                    replacement = mapping_value[0]\n                else:\n                    replacement = mapping_value[1]\n            else:\n                replacement = mapping_value\n\n        if replacement:\n            replacement = match_case(token.text, replacement)\n            result_tokens.append(replacement)\n        else:\n            result_tokens.append(token.text)\n\n    # Rebuild string with corrected spacing\n    return spacy.tokens.Doc(doc.vocab, words=result_tokens).text_with_ws.strip()\n\nexamples = [\n    (\"He is going to the market.\", \"female\"),\n    (\"His book is on the table.\", \"female\"),\n    (\"I saw him yesterday.\", \"female\"),\n    (\"He hurt himself.\", \"female\"),\n    (\"I called him last night.\", \"female\"),\n    (\"That is his car.\", \"female\"),\n    (\"He told me about his trip.\", \"female\"),\n    (\"The teacher gave him a warning.\", \"female\"),\n    (\"He blames himself for the mistake.\", \"female\"),\n    (\"He brought his laptop.\", \"female\"),\n    (\"He made it himself.\", \"female\"),\n    (\"I donâ€™t like his attitude.\", \"female\"),\n    (\"Tell him to come here.\", \"female\"),\n    (\"She is going to the market.\", \"male\"),\n    (\"Her book is on the table.\", \"male\"),\n    (\"I saw her yesterday.\", \"male\"),\n    (\"She hurt herself.\", \"male\"),\n    (\"I called her last night.\", \"male\"),\n    (\"That is her car.\", \"male\"),\n]\n\nfor text, gender in examples:\n    print(f\"Input: {text}\\nTarget: {gender}\\nOutput: {switch_gender(text, target=gender)}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T06:08:27.501092Z","iopub.execute_input":"2025-09-06T06:08:27.501428Z","iopub.status.idle":"2025-09-06T06:08:32.432953Z","shell.execute_reply.started":"2025-09-06T06:08:27.501407Z","shell.execute_reply":"2025-09-06T06:08:32.431998Z"}},"outputs":[{"name":"stdout","text":"Input: He is going to the market.\nTarget: female\nOutput: She is going to the market .\n\nInput: His book is on the table.\nTarget: female\nOutput: Her book is on the table .\n\nInput: I saw him yesterday.\nTarget: female\nOutput: I saw her yesterday .\n\nInput: He hurt himself.\nTarget: female\nOutput: She hurt herself .\n\nInput: I called him last night.\nTarget: female\nOutput: I called her last night .\n\nInput: That is his car.\nTarget: female\nOutput: That is her car .\n\nInput: He told me about his trip.\nTarget: female\nOutput: She told me about her trip .\n\nInput: The teacher gave him a warning.\nTarget: female\nOutput: The teacher gave her a warning .\n\nInput: He blames himself for the mistake.\nTarget: female\nOutput: She blames herself for the mistake .\n\nInput: He brought his laptop.\nTarget: female\nOutput: She brought her laptop .\n\nInput: He made it himself.\nTarget: female\nOutput: She made it herself .\n\nInput: I donâ€™t like his attitude.\nTarget: female\nOutput: I do nâ€™t like her attitude .\n\nInput: Tell him to come here.\nTarget: female\nOutput: Tell her to come here .\n\nInput: She is going to the market.\nTarget: male\nOutput: He is going to the market .\n\nInput: Her book is on the table.\nTarget: male\nOutput: His book is on the table .\n\nInput: I saw her yesterday.\nTarget: male\nOutput: I saw him yesterday .\n\nInput: She hurt herself.\nTarget: male\nOutput: He hurt himself .\n\nInput: I called her last night.\nTarget: male\nOutput: I called him last night .\n\nInput: That is her car.\nTarget: male\nOutput: That is his car .\n\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}